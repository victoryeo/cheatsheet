# delete all the Pending pods
kubectl -n prod get pods | grep Pending | awk '{print $1}' | xargs kubectl -n prod delete pod -o name

# test full domain name of a service
kubectl run test-dns-busybox -it --image=busybox:1.28 --rm --restart=Never -- nslookup myservice.mynamespace.svc.cluster.local

# find connection to  service is good or bad from a pod's perspective
kubectl exec -n prod my-pod -it -- sh -c 'timeout 1 bash -c "</dev/tcp/your-service/80" && echo "good" || echo "bad"'

# get and decode secret
kubectl -n <ns> get secrets/api --template={{.data.POSTGRESQL_PASSWORD}} | base64 -d

# kubectl command auto completion 
source <(kubectl completion bash)
complete -F __start_kubectl k

# watch the cronjob as they are being scheduled
kubectl get cronjob --watch

# show cronjob successfulJobsHistoryLimit
kubectl get cronjobs <job_name> -o yaml

# update nginx image to latest version
kubectl set image deployment/<deploy_name> nginx=nginx:latest

# verify rollout history
kubectl rollout history deploy <deploy_name> --revision=2

# revert the deployment to revision 1
kubectl rollout undo deployment <deploy_name> --to-revision=1

# rollout restart
kubectl -n moon rollout restart deploy <deployname>

# create a pod with nginx image and export port 80
kubectl run pod1 --image=nginx:2.3.5 --port=80  --labels project=pl6-gcc-api --dry-run=client -o yaml

# run temp pod with specific labels
kubectl run tmppod --image=busybox --restart=Never --rm -i --labels="app=todo,tier=backend" -- wget -O- 10.156.8.26:3306

# run pod with command
kubectl run pod6 --image=busybox:1.31.0 --dry-run=client -o yaml  --command -- sh -c "touch /tmp/ready && sleep 1d" > 6.yaml

# run an iterative pod
kubectl run busybox --image=busybox --rm -it -- /bin/sh
# run a temp pod and wget against clusterIP address of the service
kubectl run tmppod --image=busybox --restart=Never -it --rm -- wget -O- 10.66.220.246
kubectl run tmppod -i --rm --image=nginx:alpine --restart=Never  -- curl http://<svc_name>.<namespace>:3333

# find pod with selector value of example
kubectl get pod -l app=example

# show pod labels
kubectl get pod --show-labels=true

# show labels belonging to web and batch in prod
kubectl get pod -l 'env in (prod), tier in (web,batch)'

# unlabel a pod
kubectl label pod pod9 tier-

# label a pod based on matching selector 
kubectl label pod -l app=neptune-10ab protected=true
# set annotation based on matching selector
kubectl annotate pod -l protected=true protected="do not delete"

# check for ingress controller conflict (if got more than one ingress controller)
kubectl get svc -A | grep LoadBalancer

# get endpoint, to observe ip addresses assigned to pods
kubectl get ep

# show list of ingress
kubectl get ing -n <namespace>

# see events
kubectl get events --sort-by=.metadata.creationTimestamp -n <namespace>

# get keda scaled object from all namespaces
kubectl get scaledobject -A

# create a job
kubectl create job neb-new-job --image=busybox:1.31.0
# create cronjob
kubectl create cronjob my-job --image=busybox --schedule="*/1 * * * *" -- date
# create a generic secret with literal value
kubectl create secret generic my-secret --from-literal=db-password=speed --from-literal=password=mach5
# create secret from file
kubectl create secret generic my-secret --from-file=config.txt
# create configmap
kubectl create configmap ext-service-map --from-literal=api_endpoint=https://myapp/api --from-literal=username=traxy
kubectl -n <namespace> create configmap configmap-web-moon-html --from-file=index.html=/opt/course/15/web-moon.html


# deploy container to k8s pod
kubectl create deployment <deployment_name> --image=<container> -n <namespace>
kubectl create deployment bqdinator --image=asia.gcr.io/mycompany-blockchain-stg/bqdinator:latest -n myproject
# deploy a nginx pod
kubectl create deployment nginxapp --image=nginx:1.14.2
# deploy and expose port
kubectl create deploy myapp --image=nginx --port=80 --replicas=1 
# create quota
kubectl create quota my-quota --hard=cpu=1,memory=500M,pods=2,secrets=1 --dry-run=client -o yaml -n rq-demo 
# create service
kubectl create service clusterip myapp --tcp=80:80
# also create a service
(Using expose instead of "kubectl create service clusterip"
is faster because it already sets the correct selector-labels.)
kubectl -n <namespace> expose deployment sunny --name sun-srv --port 9999 --target-port 80
# expose a pod
kubectl -n <namespace> expose pod <podname> --name <svc_name> --port 3333 --target-port 80

# describe deployment
kubectl describe deployment <deployment_name> -n <namespace>
# describe secret
kubectl describe secret <secret_name>
# describe ingress routes
kubectl describe ingress <ingress_name> -n <namespace>
# describe pod (to find pod's external ip address)
kubectl describe pod <podname> -n <namespace> 
# get pod status
kubectl describe pod <podname> | grep -i status
# show specific ingress details
kubectl describe ing <ingress_name> -n <namespace> 

# apply k8s ingress yaml file
kubectl apply -f <k8s_yaml>.yml

# see logs
kubectl logs install-helm -n gitlab-managed-apps

# access log of previously crashed pod
kubectl logs --tail=10 <POD-NAME> -p

# see log of jobs
k logs jobs/<jobname>

# create a pod
kubectl create -f ./config-example.yaml -n <namespace>

# delete a pod
kubectl delete -f ./config-example.yaml -n <namespace>

# delete a pod
kubectl delete pod  <pod_name>  -n <namespace>

# delete a deployment
kubectl delete deployment <deployment_name> -n <namespace>

# show list of k8s contexts
kubectl config get-contexts

# use the context of cluster
kubectl config use-context <CLUSTER_NAME>

# switch namespace
kubectl config set-context --current --namespace=newns

# show current cluster
kubectl config current-context

# delete cluster from ~/.kube/config
kubectl config delete-context <CLUSTER_NAME>

# delete cluster/context/user entries
kubectl config unset users.gke_project_zone_name

kubectl config unset contexts.aws_cluster1-kubernetes

kubectl config unset clusters.foobar-baz

kubectl config get-clusters

# to connect to a pod command line
kubectl exec nginx-f89759699-2gbwc  -it -- bash
# connect to container in pod
kubectl -n <namespace> exec <pod> --container <container_name> -it -- bash
# connect to postgres container
kubectl exec -it <pod> -c postgresql -- psql -U postgres -p 5432
# enter redis pod and run redis-cli tool
kubectl exec -it redis-pod -- redis-cli
# get env variable
kubectl exec -it <pod_name> -- env

# live log
kubectl -n bc logs peer0-ade-hlf-peer-797894965c-cvrxd --tail 1 --follow
kubectl -n bc logs peer0-ade-hlf-peer-797894965c-cvrxd --tail 1 -f

# scale deployment replicas
kubectl scale deployment <name> --replicas=10

# get namespace
kubectl get namespace
# get service
kubectl get svc -n <namespace>
kubectl get service -n <namespace>
kubectl get service -n <namespace> -o wide

# get service of current context
kubectl --context CURRENT_CONTEXT get svc
kubectl --context arn:aws:eks:us-west-2:151215527701:cluster/sube-cluster-tf get svc

# copy file to a container in a specific pod
kubectl cp /home/Downloads/tokendata.csv kafka-proxy-85557c4ddb-k9zhp:/tmp/ -c postgresql

# open aws-auth configmap for editing
kubectl edit -n kube-system configmap/aws-auth
# reading aws-auth configmap
kubectl describe -n kube-system configmap/aws-auth

# to untaint nodes
kubectl taint nodes --all eks.amazonaws.com/compute-type=fargate:NoSchedule-

# to see node info
kubectl get nodes <node> -o json

# to check CSI driver version
kubectl explain CSIDriver

# check pods spec containers syntax
kubectl explain pods.spec.containers.port

# krew plugin manager, list all plugins installed
kubectl krew list

# install ctx plugin via krew
kubectl krew install ctx
kubectl ctx

# if resource-capacity plugin is installed, we can run the command
kubectl resource-capacity
